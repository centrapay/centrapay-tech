{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Centrapay Engineering",
  "language": "en",
  "home_page_url": "https://tech.centrapay.com/",
  "feed_url": "https://tech.centrapay.com/feed/feed.json",
  "description": "News and views from the Centrapay Engineering team",
  "items": [{
      "id": "https://tech.centrapay.com/posts/debugging-flaky-tests/",
      "url": "https://tech.centrapay.com/posts/debugging-flaky-tests/",
      "title": "Debugging Flaky Tests",
      "content_html": "<p>Flaky tests are unreliable tests which fail intermittently when run repeatedly\neven when no code changes are made. They are hard to reproduce and thus\ndifficult to debug. They have a tendency to degrade the effectiveness of our\ntest automation over time. This post describes some strategies for dealing with\nflaky tests.</p>\n<p>This article is written from the context of using Cucumber JS to perform\nfunctional testing of HTTP APIs.  The patterns are also applicable to other\nlanguages and other functional testing tools such as Cypress, Cucumber JVM or\nSpecflow. The patterns here are generally not applicable to unit testing,\nhowever.</p>\n<h3>What makes flaky tests so bad?</h3>\n<p>Flaky tests tend to accumulate in our tests suites because we often don't\nnotice them until long after they were written. When this happens, valuable\ncontext about what might have caused them has been lost.  When we encounter\nflaky tests we are often engaged in other unrelated work.  The intermittent\nunexpected failing test becomes a nuisance which results in us often just\nrerunning the test suite and moving on without solving the underlying issue.</p>\n<p>The presence of flaky tests causes us to distrust our test automation and slow\nour delivery pipelines as we learn to rerun failing pipeline steps and\nwait for the next green build.</p>\n<h3>What can we do about flaky tests?</h3>\n<p>There are a few simple things we can do to help keep flaky tests under control:</p>\n<ol>\n<li>Understand common causes for unreliable tests.</li>\n<li>Track failing tests over many runs with an error reporting tool.</li>\n<li>Use distributed tracing to correlate tests with application logs.</li>\n</ol>\n<p>Each of these are discussed below.</p>\n<h2>Common Causes for Flakiness</h2>\n<p>There are many causes for test flakiness. Some of the common ones are described\nbelow along with hints on how to avoid them.</p>\n<h3>Missing retry</h3>\n<p>When testing side effects from asynchronous processes there is often some\nnon-deterministic amount of time before the expected state change can be\nobserved.  Tests should retry the necessary interaction until the desired\nassertion passes. The <a href=\"https://www.npmjs.com/package/retry-assert\">Retry Assert</a> library helps to simplify this type of\nretry logic.</p>\n<h3>Random test data</h3>\n<p>Functional tests often need to generate test data that avoids collisions.\nSometimes we get unlucky and generate random values that collide. It might help\nto increase the address space or use a sequence instead of (or in addition to)\nthe random value.</p>\n<h3>Missing await</h3>\n<p>This issue is not uncommon when testing with JavaScript; a step performs an\nasynchronous operation such as calling an API but does not wait for the promise\nto resolve.  Using <code>await</code> within <code>Array.forEach()</code> can also trigger this\nissue. A <code>for</code> loop or <code>Promise.all()</code> should be preferred.  Turning on the\n<a href=\"https://eslint.org/docs/rules/require-await\">Require Await</a> linting rule can sometimes help to spot this issue earlier.</p>\n<h3>Conflicting stubbing</h3>\n<p>Functional test suites should define mocks of remote dependencies using a tool\nlike <a href=\"http://wiremock.org/\">Wiremock</a> to make tests fast and deterministic. If mocks are defined\ntoo broadly then they can inadvertently match on unrelated requests. In such\ncases the flakiness might depend on the scenario execution order and might not\nbe noticed until scenario execution order changes at a much later date.</p>\n<p>Mocks should be defined so they match only for the interactions triggered by\nthe related scenario. For example, instead of just matching on &quot;POST\n/some/resource&quot;, the stub should also try to match on some header or body\nattribute that is unique to the scenario. The <a href=\"https://www.npmjs.com/package/mock-cmdr\">Mock Commander</a> library helps\nto make targeted stubbing like this easier.</p>\n<p>As a last resort, if the stubbed endpoint does not receive enough information\nto discriminate between invocation from two different scenarios, then a unique\nscenario trace id can be forwarded to the remote endpoint and matched by the\nstub.</p>\n<h3>Inaccurate date comparison</h3>\n<p>When a test asserts on a date value that comes back from the application under\ntest (like a creation or expiry date) it needs to tolerate some\nnon-deterministic amount of delay. Some naive solutions to this problem may\nintroduce flakiness around edge cases such as when the test runs close to the\nstart of a new minute, hour, or day etc.  For this reason we have created\n<a href=\"https://www.npmjs.com/package/@centrapay/jest-date-matchers\">Jest Date Matchers</a> to make it easy to assert on ISO-8601 date strings with a\nconfigurable threshold.</p>\n<h3>Production bugs</h3>\n<p>Finally, there might actually be a real bug that is being intermittently\ntriggered by the test suite. The intermittent nature of the failure might be\ndue to race conditions when testing multiple API calls, over reliance on random\ntest data or some other non-deterministic variable such as the server time or a\nmissing <code>await</code> in production code.  If possible, the test suite should be\nchanged to reliably reproduce the failure before fixing the underlying bug.</p>\n<h2>Tracking failing tests across runs</h2>\n<p>Investigation of flaky tests can take many attempts over a long period of time\nbefore the root cause is finally discovered. It is invaluable to have a shared\nrecord that includes details about occurrences of failures as well as any\nlearnings that have been made along the way.</p>\n<p>The flaky test record could start out as a document that is updated manually\nwhen flaky tests are encountered but, to get a reliable record, the failure\ndetails should be automatically sent to an external tool.  Which tool to use is\na subjective choice that will depend on the preferences of the team. For\nexample, it may be a documentation tool, a test case management tool, a bug\ntracker or an error reporting tool.</p>\n<h3>Capturing Cucumber scenario failures</h3>\n<p>In Cucumber we can use an <a href=\"https://cucumber.io/docs/cucumber/api/#hooks\">After hook</a> to capture details about each failed\nscenario.</p>\n<pre class=\"language-javascript\"><code class=\"language-javascript\"><span class=\"token comment\">// features/support/index.js</span><br />cucumber<span class=\"token punctuation\">.</span><span class=\"token function\">After</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">scenario</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>scenario<span class=\"token punctuation\">.</span>result<span class=\"token punctuation\">.</span>status <span class=\"token operator\">==</span> <span class=\"token string\">'failed'</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />    <span class=\"token function\">captureFailedScenario</span><span class=\"token punctuation\">(</span>scenario<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<h3>Sending scenario failures to Sentry</h3>\n<p><a href=\"https://www.sentry.io/\">Sentry</a> is an error reporting tool that helps engineering teams to monitor and\ndiagnose issues with deployed software. The nature of flaky tests - being\nintermittent and long lived - makes them well-suited to being tracked by\nSentry.</p>\n<p>To send a failed Cucumber scenario to Sentry we basically just need to pass\n<code>scenario.result.exception</code> to <code>Sentry.captureException()</code>. There's a few other\nthings we should do to enhance the Sentry event though:</p>\n<ol>\n<li>Provide plenty of additional information to help identify the context for the\nfailure such as the source file, git commit, git branch and build number.</li>\n<li>Use the scenario name as the &quot;fingerprint&quot; so that all failures for the same\nscenario are treated as the same issue (and similar errors for different\nscenarios are treated as distinct issues).</li>\n<li>Set the error name with a sensible static prefix to make them searchable and\neasy to identify.</li>\n</ol>\n<p>The following function demonstrates sending a failed Cucumber scenario to Sentry:</p>\n<pre class=\"language-javascript\"><code class=\"language-javascript\"><span class=\"token keyword\">function</span> <span class=\"token function\">captureFailedScenario</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">scenario</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">const</span> scenarioName <span class=\"token operator\">=</span> scenario<span class=\"token punctuation\">.</span>pickle<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">;</span><br />  <span class=\"token keyword\">const</span> error <span class=\"token operator\">=</span> scenario<span class=\"token punctuation\">.</span>result<span class=\"token punctuation\">.</span>exception<span class=\"token punctuation\">;</span><br />  Sentry<span class=\"token punctuation\">.</span><span class=\"token function\">withScope</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">scope</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />    scope<span class=\"token punctuation\">.</span><span class=\"token function\">setContext</span><span class=\"token punctuation\">(</span><span class=\"token string\">'cucumber'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span> scenarioName<span class=\"token punctuation\">,</span> src<span class=\"token operator\">:</span> scenario<span class=\"token punctuation\">.</span>sourceLocation<span class=\"token punctuation\">.</span>uri <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    scope<span class=\"token punctuation\">.</span><span class=\"token function\">setContext</span><span class=\"token punctuation\">(</span><span class=\"token string\">'source'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span> gitBranch<span class=\"token punctuation\">,</span> gitCommit<span class=\"token punctuation\">,</span> buildNumber <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    scope<span class=\"token punctuation\">.</span><span class=\"token function\">setTag</span><span class=\"token punctuation\">(</span><span class=\"token string\">'branch'</span><span class=\"token punctuation\">,</span> gitBranch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    scope<span class=\"token punctuation\">.</span><span class=\"token function\">setFingerprint</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span> scenarioName <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    Sentry<span class=\"token punctuation\">.</span><span class=\"token function\">captureException</span><span class=\"token punctuation\">(</span><span class=\"token function\">VError</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><br />      name<span class=\"token operator\">:</span> <span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token string\">Cucumber / Failed Scenario / </span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>scenarioName<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">,</span><br />      cause<span class=\"token operator\">:</span> error<span class=\"token punctuation\">,</span><br />    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<h2>Correlating tests with application logs</h2>\n<p>When a test scenario fails, our testing tool should give us some\ncontext about the unexpected result. Hopefully we get enough information to\nimmediately identify the cause of the failure but often this is not the case,\nespecially when dealing with flaky tests.</p>\n<p>If the test runner log does not contain enough information to diagnose the\nfailure then the next port of call is the application logs. Unfortunately, when\ndealing with intermittent test failures, the relevant log entries will\nprobably be lost in a sea of similar and unrelated log entries.</p>\n<p>To make the application logs searchable we need to apply distributed tracing\ntechniques when running our test suite. One way to achieve this is to include\nthe test name in an HTTP tracing header and make sure it is logged by the\napplication server.</p>\n<h3>Sending a scenario trace header</h3>\n<p>The test suite can use a custom HTTP client abstraction to ensure a trace\nheader is included for every request to the application under test.  In the\nexample below, the &quot;AppClient&quot; instance, and its traceId, will be scoped to the\ntest scenario. The AppClient will ensure the <code>traceId</code> attribute is included\nin an HTTP header (eg <code>X-Trace-Id</code>) for every request.</p>\n<pre class=\"language-javascript\"><code class=\"language-javascript\"><span class=\"token comment\">// features/support/index.js</span><br />cucumber<span class=\"token punctuation\">.</span><span class=\"token function\">Before</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">scenario</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>appClient <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AppClient</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><br />    traceId<span class=\"token operator\">:</span> scenario<span class=\"token punctuation\">.</span>pickle<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">,</span><br />  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>If the application's web server is configured to log this header for all\nrequests then it will now be possible to identify which logs relate to a\nspecific test.</p>\n<h3>Accessing ephemeral test logs</h3>\n<p>Sometimes the intermittent failure has occurred during a CI pipeline step. In\nthese cases we need to be able to get access to the application logs from the\nCI environment.</p>\n<p>If Docker Compose is used to stand up an ephemeral instance of an application\nwithin the CI environment then we may also need to run <code>docker compose logs</code> to\nexport the application logs. The following bash script runs a test suite with\nDocker Compose and captures all logs:</p>\n<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token shebang important\">#!/bin/bash</span><br /><span class=\"token builtin class-name\">set</span> -euo pipefail<br />docker compose run cucumber <span class=\"token operator\">|</span> <span class=\"token function\">tee</span> cucumber.log <span class=\"token operator\">||</span> <span class=\"token assign-left variable\">failed</span><span class=\"token operator\">=</span>yes<br />docker compose logs --no-color <span class=\"token operator\">></span> docker-compose.log<br /><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span> -z <span class=\"token string\">\"<span class=\"token variable\">${failed<span class=\"token operator\">:-</span>}</span>\"</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">||</span> <span class=\"token builtin class-name\">exit</span> <span class=\"token number\">1</span></code></pre>\n<p>If our pipeline runner captures these log files as artifacts then we will be\nable to investigate test failures even when we cannot reproduce them locally.</p>\n<h2>Summary</h2>\n<p>Flaky tests are inevitable. When too many flaky tests creep into a test suite\nthey undermine the value of the automation.</p>\n<p>Keeping flaky tests under control requires conscious effort from the software\ndelivery team.  Linking application logs to test scenarios and tracking\nrecurring failures are two simple enhancements to test tooling that aids this\neffort.</p>\n",
      "date_published": "2021-10-26T00:00:00Z"
    }
  ]
}
